%\documentclass[12pt]{report}
%
%% some macros
%\input{notation}
%\input{includes}
%
%\begin{document}

\chapter{Introduction}

Whole section needs rewriting...

Visual speech prediction, often referred to as lip reading, is a very difficult task, partly due to ambiguities between phonemes such as '\textit{p}' and '\textit{b}', which look the same but sound different.
Current methods of addressing this problem focus on training deep learning models using 2D temporal data of people speaking with the relevant video frames labelled with the correct spoken text \cite{Chung2016, Assael2016, Chung2017, Shillingford2018}.
There currently do not exist any models which attempt to address this problem with the use of 3D temporal datasets made up of head scans of subjects, capturing depth and thus, more information of the mouth which may be of use to the models.
However, there currently exists a severe lack of availability of such datasets due to the complexity and hardware requirements in capturing such data.
Currently their exists two publicly available datasets: LRW-3D \cite{Tzirakis2019} and the VOCASET \cite{Cudeiro2019}, both of which are relatively small in comparison to the models used in current lip reading models.
To first attempt this problem, new datasets which capture 3D temporal models of subjects heads speaking must be established by the community.
As well as capturing new data, expanding existing datasets with generated synthetic data with the use of generative adversarial networks may assist in the solution to this problem.

In an attempt to add variation to sampled generated from a model, a Generative Adversarial Network is proposed which can be trained end-to-end from audio inputs to drive a 3D template mesh.
This shall be achieved by initially using the...

\begin{itemize}

    \item What is the problem?
    \item Current solutions
    \item Issues with current solutions
    \item Your observation / proposition

\end{itemize}

%\bibliographystyle{unsrt}
%\bibliography{ref}
%\end{document}